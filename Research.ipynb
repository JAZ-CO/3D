{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JAZ-CO/3D/blob/main/Research.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mispronunciation Detection and Diagnosis (MDD) for Arabic Learners using Generative AI**\n",
        "\n",
        "**Outlines:**\n",
        "\n",
        "\n",
        "*  Explore AI tools for Arabic Speech Recognition:\n",
        "    1. Azure\n",
        "    2. Google\n",
        "    3. OpenAI Whisper\n",
        "*  Datasets:\n",
        "    1. ASMDD: https://drive.google.com/drive/folders/1dhlp-L0n6_RAzoosVK4bRa7hxBnzebqs\n",
        "    2. MGB-3: https://huggingface.co/datasets/MightyStudent/Egyptian-ASR-MGB-3/viewer?views%5B%5D=train\n",
        "    3. QASR or any dataset from news\n",
        "*  Benchmark each tool with metrics:\n",
        "      1.   Word Error Rate (WER): Measures transcription errors\n",
        "      2.   Character Error Rate (CER): Useful for languages with complex scripts\n",
        "      3.   Speaker Diarization Error Rate (DER): Accuracy in differentiating speakers\n",
        "      4.   Processing Speed (Latency): Time taken for transcription\n",
        "      5.   Noise Handling: Performance in different noise environments\n",
        "      6.   Accent and Dialect Support: Accuracy for diverse accents\n",
        "      7.   CPU/GPU Usage: Efficiency in processing\n",
        "      8.   Memory Consumption: RAM requirements\n",
        "      9.   Cloud vs. Local Processing\n",
        "      10.  Cost Comparison\n",
        "\n",
        "*  Conclusion\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fUxK60F9Ut5R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install azure-cognitiveservices-speech"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjoudsXXnJPa",
        "outputId": "89be9e67-5de4-4d43-fc9f-dd98c3bb526a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting azure-cognitiveservices-speech\n",
            "  Downloading azure_cognitiveservices_speech-1.42.0-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Downloading azure_cognitiveservices_speech-1.42.0-py3-none-manylinux1_x86_64.whl (39.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.7/39.7 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: azure-cognitiveservices-speech\n",
            "Successfully installed azure-cognitiveservices-speech-1.42.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jiwer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_V40vrwDyqfa",
        "outputId": "8753ff7f-a4e0-4006-d56b-69e3ed1fcef7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jiwer\n",
            "  Downloading jiwer-3.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from jiwer) (8.1.8)\n",
            "Collecting rapidfuzz>=3.9.7 (from jiwer)\n",
            "  Downloading rapidfuzz-3.12.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Downloading jiwer-3.1.0-py3-none-any.whl (22 kB)\n",
            "Downloading rapidfuzz-3.12.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, jiwer\n",
            "Successfully installed jiwer-3.1.0 rapidfuzz-3.12.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import psutil\n",
        "import time\n",
        "import subprocess\n",
        "\n",
        "def get_system_usage():\n",
        "    counter = time.perf_counter()\n",
        "    return counter\n",
        "\n",
        "# # Measure before execution\n",
        "# cpu_before, gpu_before, mem_before = get_system_usage()\n",
        "\n",
        "# # Measure after execution\n",
        "# cpu_after, gpu_after, mem_after = get_system_usage()\n",
        "\n",
        "# # Calculate differences\n",
        "# cpu_diff = cpu_after - cpu_before\n",
        "# gpu_diff = gpu_after - gpu_before\n",
        "# mem_diff = mem_after - mem_before  # Memory difference in bytes\n",
        "\n",
        "# # Display results\n",
        "# print(f\"CPU Usage Change: {cpu_diff:.2f}%\")\n",
        "# print(f\"GPU Usage Change: {gpu_diff:.2f}%\")\n",
        "# print(f\"Memory Usage Change: {mem_diff / (1024 ** 2):.2f} MB\")  # Convert bytes to MB\n"
      ],
      "metadata": {
        "id": "vsZft4vt1RYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Given a bunch of arabic text label and a corresponding transcriped arabic text from AI tool, I want to implement these benchmacrks:\n",
        "#       1.   Word Error Rate (WER): Measures transcription errors\n",
        "#       2.   Character Error Rate (CER): Useful for languages with complex scripts\n",
        "#       4.   Processing Speed (Latency): Time taken for transcription\n",
        "#       7.   CPU/GPU Usage: Efficiency in processing\n",
        "#       8.   Memory Consumption: RAM requirements\n",
        "\n",
        "import time\n",
        "import jiwer\n",
        "import psutil\n",
        "import os\n",
        "\n",
        "# ... (Your existing code for Azure, Google, and Whisper APIs) ...\n",
        "\n",
        "\n",
        "def calculate_metrics(ground_truth, hypothesis):\n",
        "    \"\"\"Calculates WER, CER, and other metrics.\"\"\"\n",
        "\n",
        "    # Word Error Rate (WER)\n",
        "    wer = jiwer.wer([ground_truth], hypothesis)\n",
        "\n",
        "    # Character Error Rate (CER)\n",
        "    cer = jiwer.cer(ground_truth, hypothesis)\n",
        "\n",
        "    return wer, cer\n",
        "\n",
        "\n",
        "def benchmark(ground_truth_texts, hypothesis_texts, delta_time):\n",
        "  number_of_texts = 0\n",
        "  total_wer = 0\n",
        "  total_cer = 0\n",
        "  not_transcribed = 0\n",
        "  for gt, hyp in zip(ground_truth_texts, hypothesis_texts):\n",
        "      if(isinstance(hyp, str)):\n",
        "\n",
        "        wer, cer = calculate_metrics(gt, hyp)\n",
        "\n",
        "        number_of_texts += 1\n",
        "        total_wer += wer\n",
        "        total_cer += cer\n",
        "      else:\n",
        "        not_transcribed += 1\n",
        "  if(number_of_texts >0):\n",
        "    average_wer = total_wer / number_of_texts\n",
        "    average_cer = total_cer/ number_of_texts\n",
        "\n",
        "    print(f\"  Average WER: {average_wer:.4f}\")\n",
        "    print(f\"  Average CER: {average_cer:.4f}\")\n",
        "    print(f\"  Latency: {delta_time:.4f} seconds\")\n",
        "    print(f\"  Not transcripted: {not_transcribed} words\")\n",
        "\n",
        "    return average_wer, average_cer, delta_time, not_transcribed\n",
        "  else:\n",
        "    print(\"   Nothing got transcripted\")\n",
        "    return 100,100,delta_time,not_transcribed\n",
        "\n",
        "# # Example usage (replace with your actual data)\n",
        "# ground_truth_texts = [\"السلام عليكم ورحمة الله وبركاته\", \"كيف حالك؟\"]\n",
        "# hypothesis_texts = [\"السلام عليكم ورحمة الله\", \"كيف حالك\"]\n",
        "# benchmark(ground_truth_texts, hypothesis_texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "Z565UC-Asl8_",
        "outputId": "1aa04213-c0a5-457f-bdf4-35c2465998c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "expected string or bytes-like object, got 'list'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-72-7d78285551b7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdelta_time\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnot_transcribed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalculate_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"one\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"two\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"on\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"two\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;31m# # Example usage (replace with your actual data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;31m# ground_truth_texts = [\"السلام عليكم ورحمة الله وبركاته\", \"كيف حالك؟\"]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-72-7d78285551b7>\u001b[0m in \u001b[0;36mcalculate_metrics\u001b[0;34m(ground_truth, hypothesis)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Word Error Rate (WER)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mwer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjiwer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mground_truth\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhypothesis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# Character Error Rate (CER)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jiwer/measures.py\u001b[0m in \u001b[0;36mwer\u001b[0;34m(reference, hypothesis, reference_transform, hypothesis_transform, truth, truth_transform)\u001b[0m\n\u001b[1;32m    109\u001b[0m     )\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m     output = process_words(\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0mreference\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhypothesis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreference_transform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhypothesis_transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jiwer/process.py\u001b[0m in \u001b[0;36mprocess_words\u001b[0;34m(reference, hypothesis, reference_transform, hypothesis_transform)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;31m# pre-process reference and hypothesis by applying transforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m     ref_transformed = _apply_transform(\n\u001b[0m\u001b[1;32m    169\u001b[0m         \u001b[0mreference\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreference_transform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_reference\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jiwer/process.py\u001b[0m in \u001b[0;36m_apply_transform\u001b[0;34m(sentence, transform, is_reference)\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;31m# Apply transforms. The transforms should collapse input to a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0;31m# list with lists of words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m     \u001b[0mtransformed_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;31m# Validate the output is a list containing lists of strings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jiwer/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jiwer/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jiwer/transforms.py\u001b[0m in \u001b[0;36mprocess_list\u001b[0;34m(self, inp)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprocess_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jiwer/transforms.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprocess_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jiwer/transforms.py\u001b[0m in \u001b[0;36mprocess_string\u001b[0;34m(self, s)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprocess_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"\\s\\s+\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprocess_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/re/__init__.py\u001b[0m in \u001b[0;36msub\u001b[0;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0ma\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mMatch\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmust\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     a replacement string to be used.\"\"\"\n\u001b[0;32m--> 185\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msubn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object, got 'list'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Implement Azure AI Arabic Speech to Text using audio file\n",
        "\n",
        "# Import necessary libraries\n",
        "import azure.cognitiveservices.speech as speechsdk\n",
        "\n",
        "# Replace with your Azure Speech service subscription key and region\n",
        "\n",
        "\n",
        "# Replace with the path to your Arabic audio file\n",
        "# audio_file_path = \"/content/audio (1).wav\"  # Example: \"/content/audio.wav\"\n",
        "\n",
        "\n",
        "def transcribe_arabic_azure(audio_file_path):\n",
        "    \"\"\"Performs speech-to-text recognition using Azure Speech service.\"\"\"\n",
        "\n",
        "    speech_key, service_region = \"CDGcTgsSt5N28RmKxnBWe4JAPob4j61RJXY2EfBL2apIZKXbkOsMJQQJ99BBACYeBjFXJ3w3AAAYACOGccdX\", \"eastus\"\n",
        "    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n",
        "\n",
        "    # Set the language to Arabic (adjust if needed)\n",
        "    speech_config.speech_recognition_language = \"ar-EG\"  # Example: Egyptian Arabic\n",
        "    audio_config = speechsdk.audio.AudioConfig(filename=audio_file_path)\n",
        "\n",
        "    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)\n",
        "    # print(\"Recognizing speech from audio file...\")\n",
        "\n",
        "    result = speech_recognizer.recognize_once_async().get()\n",
        "\n",
        "    if result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
        "        # print(\"Recognized: {}\".format(result.text))\n",
        "        return result.text\n",
        "    elif result.reason == speechsdk.ResultReason.NoMatch:\n",
        "        print(\"No speech could be recognized: {}\".format(result.no_match_details))\n",
        "    elif result.reason == speechsdk.ResultReason.Canceled:\n",
        "        cancellation_details = result.cancellation_details\n",
        "        print(\"Speech Recognition canceled: {}\".format(cancellation_details.reason))\n",
        "        if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
        "            print(\"Error details: {}\".format(cancellation_details.error_details))\n",
        "\n",
        "# Example usage\n",
        "# transcribe_arabic_azure(audio_file_path)\n"
      ],
      "metadata": {
        "id": "zsMQ3YjTVvIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SpeechRecognition"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmqSrwioqXHf",
        "outputId": "1664e841-934d-4ac2-90c6-42b0dca4203a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting SpeechRecognition\n",
            "  Downloading SpeechRecognition-3.14.1-py3-none-any.whl.metadata (31 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from SpeechRecognition) (4.12.2)\n",
            "Downloading SpeechRecognition-3.14.1-py3-none-any.whl (32.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.9/32.9 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: SpeechRecognition\n",
            "Successfully installed SpeechRecognition-3.14.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Google Speech to Text**"
      ],
      "metadata": {
        "id": "-InoCZkspzvn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Use Google Speech to text for Arabic using audio file\n",
        "\n",
        "import speech_recognition as sr\n",
        "\n",
        "# Replace with the path to your Arabic audio file\n",
        "audio_file_path = \"/content/audio (1).wav\"  # Example: \"/content/audio.wav\"\n",
        "\n",
        "def transcribe_arabic_google(audio_file_path):\n",
        "    \"\"\"Performs speech-to-text recognition using Google Speech Recognition.\"\"\"\n",
        "    r = sr.Recognizer()\n",
        "    with sr.AudioFile(audio_file_path) as source:\n",
        "        audio = r.record(source)  # read the entire audio file\n",
        "\n",
        "    try:\n",
        "        # Use the Arabic language model\n",
        "        text = r.recognize_google(audio, language=\"ar-EG\")  # or another Arabic variant like \"ar-SA\"\n",
        "        # print(\"Recognized Text:\", text)\n",
        "        return text\n",
        "    except sr.UnknownValueError:\n",
        "        print(\"   Google Speech Recognition could not understand audio\")\n",
        "    except sr.RequestError as e:\n",
        "        print(f\"    Could not request results from Google Speech Recognition service; {e}\")\n",
        "\n",
        "# Example usage\n",
        "# transcribe_arabic_google(audio_file_path)\n"
      ],
      "metadata": {
        "id": "UAtxMdJypzvn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U openai-whisper"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JH17wZP3tAVU",
        "outputId": "3a9fb4a9-8173-4680-e23c-921379a3eafd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai-whisper\n",
            "  Downloading openai-whisper-20240930.tar.gz (800 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/800.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m645.1/800.5 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.5/800.5 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.61.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (2.5.1+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (4.67.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (10.6.0)\n",
            "Collecting tiktoken (from openai-whisper)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: triton>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from triton>=2.0.0->openai-whisper) (3.17.0)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper) (0.44.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->openai-whisper)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->openai-whisper) (3.0.2)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m67.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m130.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m87.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m113.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803373 sha256=d0aa4831be9b470b53080f32094963d392aba1a61ad24aeb61ee4b2aaebea478\n",
            "  Stored in directory: /root/.cache/pip/wheels/2f/f2/ce/6eb23db4091d026238ce76703bd66da60b969d70bcc81d5d3a\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, openai-whisper\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 openai-whisper-20240930 tiktoken-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Whisper AI**"
      ],
      "metadata": {
        "id": "Trv0j6imszQP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Use Whisper AI Speech to text for Arabic using audio file\n",
        "\n",
        "import whisper\n",
        "\n",
        "\n",
        "model =  whisper.load_model(\"small\") # or choose another model size like \"small\", \"medium\", \"large\"\n",
        "\n",
        "def transcribe_arabic_whisper(audio_file_path):\n",
        "    \"\"\"Transcribes Arabic speech using OpenAI Whisper.\"\"\"\n",
        "    try:\n",
        "        result = model.transcribe(audio_file_path, language='ar') # Specify Arabic language\n",
        "        # print(\"Recognized Text:\", result[\"text\"])\n",
        "        return result[\"text\"]\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "# Example usage\n",
        "# audio_file_path = \"/content/audio (1).wav\"  # Replace with your audio file path\n",
        "# transcribe_arabic_whisper(audio_file_path,model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cabca14-80db-421b-ff77-d4123bab670c",
        "id": "mip3qsidszQQ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 461M/461M [00:08<00:00, 53.8MiB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MP3 Dataset**"
      ],
      "metadata": {
        "id": "FckxBFm8Vksq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: just print the response from this api\n",
        "# curl -X GET \\\n",
        "#      \"https://datasets-server.huggingface.co/rows?dataset=MightyStudent%2FEgyptian-ASR-MGB-3&config=default&split=train&offset=0&length=100\"\n",
        "\n",
        "import requests\n",
        "import tempfile\n",
        "\n",
        "def download_audio(url):\n",
        "    \"\"\"Downloads an audio file from a URL and saves it temporarily.\"\"\"\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        temp_audio = tempfile.NamedTemporaryFile(delete=False, suffix=\".wav\")\n",
        "        temp_audio.write(response.content)\n",
        "        temp_audio.close()\n",
        "        print(temp_audio.name)\n",
        "        return temp_audio.name\n",
        "    else:\n",
        "        raise Exception(f\"Failed to download audio file, status code: {response.status_code}\")\n",
        "\n",
        "\n",
        "\n",
        "def api_response(url):\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()  # Raise an exception for bad status codes (4xx or 5xx)\n",
        "\n",
        "        return response.json()\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error: {e}\")\n",
        "\n",
        "url = \"https://datasets-server.huggingface.co/rows?dataset=MightyStudent%2FEgyptian-ASR-MGB-3&config=default&split=train&offset=0&length=100\"\n",
        "response = api_response(url)\n",
        "\n",
        "# print(response)\n",
        "# print(response[\"features\"][0])\n",
        "# print(response[\"rows\"])\n",
        "# print(response[\"rows\"][0][\"row\"][\"audio\"][0][\"src\"])\n",
        "# print(response[\"rows\"][0][\"row\"][\"sentence\"])\n",
        "# download_audio(response[\"rows\"][0][\"row\"][\"audio\"][0][\"src\"])\n",
        "\n",
        "ground_truth_texts = []\n",
        "transcribed_text_google = []\n",
        "\n",
        "transcribed_text_whisper = []\n",
        "\n",
        "transcribed_text_azure = []\n",
        "\n",
        "azure_time = 0\n",
        "whisper_time = 0\n",
        "google_time = 0\n",
        "\n",
        "for i, row in enumerate(response[\"rows\"]):\n",
        "\n",
        "    if(i ==5):\n",
        "      break\n",
        "    audio_url = row[\"row\"][\"audio\"][0][\"src\"]\n",
        "    sentence = row[\"row\"][\"sentence\"]\n",
        "\n",
        "    ground_truth_texts.append(sentence)\n",
        "\n",
        "    audio_file_path = download_audio(audio_url)\n",
        "\n",
        "\n",
        "    whisper_time = get_system_usage()\n",
        "    transcribed_text_whisper.append(transcribe_arabic_whisper(audio_file_path))\n",
        "    new_whisper_time = get_system_usage()\n",
        "    whisper_time = new_whisper_time-whisper_time\n",
        "\n",
        "\n",
        "    google_time = get_system_usage()\n",
        "    transcribed_text_google.append(transcribe_arabic_google(audio_file_path))\n",
        "    new_google_time = get_system_usage()\n",
        "    google_time = new_google_time-google_time\n",
        "\n",
        "    azure_time = get_system_usage()\n",
        "    transcribed_text_azure.append(transcribe_arabic_azure(audio_file_path))\n",
        "    new_azure_time = get_system_usage()\n",
        "    azure_time = new_azure_time-azure_time\n",
        "\n"
      ],
      "metadata": {
        "id": "aZXoO21AMjhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Google Bechmark\")\n",
        "benchmark(ground_truth_texts,transcribed_text_google, google_time)\n",
        "print(\"Whisper Bechmark\")\n",
        "benchmark(ground_truth_texts,transcribed_text_whisper, whisper_time)\n",
        "print(\"Azure Bechmark\")\n",
        "benchmark(ground_truth_texts,transcribed_text_azure,azure_time)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xsykeof_7t50",
        "outputId": "ae5dc510-549f-420c-a84d-1e8735857036"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Google Bechmark\n",
            "Average WER: 0.7374\n",
            "Average CER: 0.6444\n",
            "Latency: 1.9629 seconds\n",
            "Whisper Bechmark\n",
            "Average WER: 0.8166\n",
            "Average CER: 0.5585\n",
            "Latency: 10.8000 seconds\n",
            "Azure Bechmark\n",
            "Average WER: 0.7845\n",
            "Average CER: 0.6059\n",
            "Latency: 2.8386 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Results:**\n",
        "\n",
        "The labels provided by MGB3 were already not accurate because it includes English words for some reason\n",
        "\n",
        "But comparing between three models:\n",
        "\n",
        "1- Google had the best overall results\n",
        "\n",
        "2- Azure is second with better CER than Google\n",
        "\n",
        "3- Whisper was worst using small model with high latecny and WER but with best CER"
      ],
      "metadata": {
        "id": "Pv1RMY8Exl1E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import re\n",
        "\n",
        "# Define paths\n",
        "zip_path = \"/content/ASMDD.zip\"  # Update with actual ZIP path\n",
        "extract_path = \"/content\"  # Update with the desired extraction path\n",
        "\n",
        "# Step 1: Extract the ZIP file\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "# Step 2: Get a sorted list of files\n",
        "def extract_number(filename):\n",
        "    \"\"\" Extracts leading numeric part from a filename for sorting. \"\"\"\n",
        "    match = re.search(r'\\d+', filename)\n",
        "    return int(match.group()) if match else float('inf')  # If no number, put it at the end\n",
        "\n",
        "# List all files in the extracted path\n",
        "files = sorted(os.listdir(extract_path), key=lambda x: (extract_number(x), x))\n",
        "\n",
        "# Print sorted files\n",
        "print(\"\\n\".join(files))\n"
      ],
      "metadata": {
        "id": "R6xi8bHbea6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MP3 Dataset**"
      ],
      "metadata": {
        "id": "r2J_0A9aVdDn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import tempfile\n",
        "import os\n",
        "import wave\n",
        "import contextlib\n",
        "import re\n",
        "\n",
        "\n",
        "# Step 2: Iterate through extracted folders and process `.wav` files\n",
        "\n",
        "arabic_words = [\n",
        "    \"نعم\", \"رجل\", \"يخبر\",\"شخص\" ,\"الوقت\", \"اليوم\", \"صحيح\", \"أستطيع\", \"شكرا\", \"الناس\",\n",
        "    \"أعلم\", \"رائع\", \"مرحبا\", \"آسف\", \"تعال\", \"بالطبع\", \"العالم\", \"الحقيقة\", \"الليلة\", \"أمي\",\n",
        "    \"الطريق\", \"عمل\", \"الجميع\", \"جيدة\", \"المال\", \"الذهاب\", \"أرجوك\", \"المنزل\", \"الحياة\", \"انتظر\",\n",
        "    \"الرجال\", \"الله\",\"الباب\", \"جميل\", \"الشرطة\", \"السيارة\",\"عظيم\", \"الخير\", \"حالك\", \"للغاية\", \"فتاة\",\n",
        "    \"كبيرة\", \"آسفة\", \"الأرض\", \"البيت\", \"صباح\", \"ألم\", \"لحظة\", \"بالضبط\",\n",
        "]\n",
        "\n",
        "# \"رقم\", \"طريق\",\n",
        "    # \"المدينة\", \"الرئيس\", \"صديقي\", \"ساعة\", \"غرفة\", \"عام\", \"الأطفال\", \"سنة\", \"المدرسة\", \"الصباح\",\n",
        "    # \"الماء\", \"التحدث\", \"الساعة\", \"الليل\", \"نهاية\", \"حياة\", \"الواقع\", \"الطفل\", \"دكتور\", \"الهاتف\",\n",
        "    # \"الطعام\",\"فريق\", \"الفتى\",\"اللقاء\", \"نظرة\",\"النساء\", \"العشاء\",\"الأسبوع\", \"ولد\", \"رسالة\", \"عائلة\", \"القائد\", \"المرأة\",\n",
        "    # \"المرأة\",\"الطبيب\", \"اسم\", \"النقود\", \"الكلام\", \"مدينة\", \"مساء\", \"الشمس\",\"ارجوك\", \"السماء\",\"الزواج\",\"أصدقاء\",\n",
        "    # \"مكتب\",\"البحر\",\"الكتاب\",\"الشارع\",\n",
        "\n",
        "ground_truth_texts = arabic_words\n",
        "transcribed_text_google = []\n",
        "\n",
        "transcribed_text_whisper = []\n",
        "\n",
        "transcribed_text_azure = []\n",
        "azure_time = 0\n",
        "whisper_time = 0\n",
        "google_time = 0\n",
        "\n",
        "google_WERs =[]\n",
        "google_CERs =[]\n",
        "google_latecys =[]\n",
        "google_not_transcripted = 0\n",
        "whisper_WERs =[]\n",
        "whisper_CERs =[]\n",
        "whisper_latecys =[]\n",
        "whisper_not_transcripted = 0\n",
        "azure_WERs =[]\n",
        "azure_CERs =[]\n",
        "azure_latecys =[]\n",
        "azure_not_transcripted = 0\n",
        "\n",
        "#number of folders\n",
        "i=0\n",
        "\n",
        "for root, dirs, files in os.walk(extract_path):\n",
        "\n",
        "    for j,file in enumerate(files):\n",
        "      if(j<50):\n",
        "        if file.endswith(\".wav\"):\n",
        "            match = re.search(r'\\d+', file)  # Find the first occurrence of digits\n",
        "\n",
        "\n",
        "            file_path = os.path.join(root, file)\n",
        "\n",
        "\n",
        "            google_time = get_system_usage()\n",
        "            transcribed_text = transcribe_arabic_google(file_path)\n",
        "            if(transcribed_text != None):\n",
        "              transcribed_text_google.append(transcribed_text)\n",
        "              new_google_time = get_system_usage()\n",
        "              google_time = new_google_time-google_time\n",
        "              wer, cer = calculate_metrics(ground_truth_texts[int(match.group())],transcribed_text)\n",
        "              google_WERs.append(wer)\n",
        "              google_CERs.append(cer)\n",
        "              google_latecys.append(google_time)\n",
        "            else:\n",
        "              google_not_transcripted +=1\n",
        "              google_WERs.append(100)\n",
        "              google_CERs.append(100)\n",
        "              google_latecys.append(google_time)\n",
        "\n",
        "            whisper_time = get_system_usage()\n",
        "            transcribed_text = transcribe_arabic_whisper(file_path)\n",
        "            transcribed_text_whisper.append(transcribed_text)\n",
        "            if(transcribed_text != None):\n",
        "              new_whisper_time = get_system_usage()\n",
        "              whisper_time = new_whisper_time-whisper_time\n",
        "              wer, cer = calculate_metrics(ground_truth_texts[int(match.group())],transcribed_text)\n",
        "              whisper_WERs.append(wer)\n",
        "              whisper_CERs.append(cer)\n",
        "              whisper_latecys.append(whisper_time)\n",
        "            else:\n",
        "              whisper_not_transcripted +=1\n",
        "              whisper_WERs.append(100)\n",
        "              whisper_CERs.append(100)\n",
        "              whisper_latecys.append(whisper_time)\n",
        "\n",
        "\n",
        "            azure_time = get_system_usage()\n",
        "            transcribed_text = transcribe_arabic_azure(file_path)\n",
        "            transcribed_text_azure.append(transcribed_text)\n",
        "            if(transcribed_text != None):\n",
        "              new_azure_time = get_system_usage()\n",
        "              azure_time = new_azure_time-azure_time\n",
        "              wer, cer = calculate_metrics(ground_truth_texts[int(match.group())],transcribed_text)\n",
        "              azure_WERs.append(wer)\n",
        "              azure_CERs.append(cer)\n",
        "              azure_latecys.append(azure_time)\n",
        "            else:\n",
        "              azure_not_transcripted +=1\n",
        "              azure_WERs.append(100)\n",
        "              azure_CERs.append(100)\n",
        "              azure_latecys.append(whisper_time)\n",
        "\n",
        "\n",
        "    print(\"Google Bechmark\")\n",
        "    print(f\"  Average WER: {sum(google_WERs)/len(google_WERs) if len(google_WERs)!=0 else 0}\")\n",
        "    print(f\"  Average CER: {sum(google_CERs)/len(google_CERs) if len(google_CERs)!=0 else 0}\")\n",
        "    print(f\"  Latency: {sum(google_latecys)} seconds\")\n",
        "    print(f\"  Not transcripted: {google_not_transcripted} words\")\n",
        "    print(\"Whisper Bechmark\")\n",
        "\n",
        "    print(f\"  Average WER: {sum(whisper_WERs)/len(whisper_WERs) if len(whisper_WERs)!=0 else 0}\")\n",
        "    print(f\"  Average CER: {sum(whisper_CERs)/len(whisper_CERs) if len(whisper_CERs)!=0 else 0}\")\n",
        "    print(f\"  Latency: {sum(whisper_latecys)} seconds\")\n",
        "    print(f\"  Not transcripted: {whisper_not_transcripted} words\")\n",
        "\n",
        "    print(\"Azure Bechmark\")\n",
        "    print(f\"  Average WER: {sum(azure_WERs)/len(azure_WERs) if len(azure_WERs)!=0 else 0}\")\n",
        "    print(f\"  Average CER: {sum(azure_CERs)/len(azure_CERs) if len(azure_CERs)!=0 else 0}\")\n",
        "    print(f\"  Latency: {sum(azure_latecys)} seconds\")\n",
        "    print(f\"  Not transcripted: {azure_not_transcripted} words\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KruTWbv7VdDn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "db7e8c73-1f6b-4534-8e18-795d27cfcc1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google Bechmark\n",
            "  Average WER: 0\n",
            "  Average CER: 0\n",
            "  Latency: 0 seconds\n",
            "  Not transcripted: 0 words\n",
            "Whisper Bechmark\n",
            "  Average WER: 0\n",
            "  Average CER: 0\n",
            "  Latency: 0 seconds\n",
            "  Not transcripted: 0 words\n",
            "Azure Bechmark\n",
            "  Average WER: 0\n",
            "  Average CER: 0\n",
            "  Latency: 0 seconds\n",
            "  Not transcripted: 0 words\n",
            "Google Bechmark\n",
            "  Average WER: 0\n",
            "  Average CER: 0\n",
            "  Latency: 0 seconds\n",
            "  Not transcripted: 0 words\n",
            "Whisper Bechmark\n",
            "  Average WER: 0\n",
            "  Average CER: 0\n",
            "  Latency: 0 seconds\n",
            "  Not transcripted: 0 words\n",
            "Azure Bechmark\n",
            "  Average WER: 0\n",
            "  Average CER: 0\n",
            "  Latency: 0 seconds\n",
            "  Not transcripted: 0 words\n",
            "Google Bechmark\n",
            "  Average WER: 0\n",
            "  Average CER: 0\n",
            "  Latency: 0 seconds\n",
            "  Not transcripted: 0 words\n",
            "Whisper Bechmark\n",
            "  Average WER: 0\n",
            "  Average CER: 0\n",
            "  Latency: 0 seconds\n",
            "  Not transcripted: 0 words\n",
            "Azure Bechmark\n",
            "  Average WER: 0\n",
            "  Average CER: 0\n",
            "  Latency: 0 seconds\n",
            "  Not transcripted: 0 words\n",
            "Google Bechmark\n",
            "  Average WER: 0\n",
            "  Average CER: 0\n",
            "  Latency: 0 seconds\n",
            "  Not transcripted: 0 words\n",
            "Whisper Bechmark\n",
            "  Average WER: 0\n",
            "  Average CER: 0\n",
            "  Latency: 0 seconds\n",
            "  Not transcripted: 0 words\n",
            "Azure Bechmark\n",
            "  Average WER: 0\n",
            "  Average CER: 0\n",
            "  Latency: 0 seconds\n",
            "  Not transcripted: 0 words\n",
            "Google Bechmark\n",
            "  Average WER: 0\n",
            "  Average CER: 0\n",
            "  Latency: 0 seconds\n",
            "  Not transcripted: 0 words\n",
            "Whisper Bechmark\n",
            "  Average WER: 0\n",
            "  Average CER: 0\n",
            "  Latency: 0 seconds\n",
            "  Not transcripted: 0 words\n",
            "Azure Bechmark\n",
            "  Average WER: 0\n",
            "  Average CER: 0\n",
            "  Latency: 0 seconds\n",
            "  Not transcripted: 0 words\n",
            "Google Speech Recognition could not understand audio\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "list index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-76-3f0c9d3dd49c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m               \u001b[0mnew_whisper_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_system_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m               \u001b[0mwhisper_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_whisper_time\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mwhisper_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m               \u001b[0mwer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mground_truth_texts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtranscribed_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m               \u001b[0mwhisper_WERs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m               \u001b[0mwhisper_CERs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "# print(\"Google:\",transcribed_text_google)\n",
        "# print(\"Whisper:\",transcribed_text_whisper)\n",
        "# print(\"Azure:\",transcribed_text_azure)\n",
        "\n",
        "# print(\"Google match:\",set(ground_truth_texts) & set(transcribed_text_google))\n",
        "# print(\"Whisper match:\",set(ground_truth_texts) & set(transcribed_text_whisper))\n",
        "# print(\"Azure match:\",set(ground_truth_texts) & set(transcribed_text_azure))"
      ],
      "metadata": {
        "id": "DMAYnOFbVdDn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}